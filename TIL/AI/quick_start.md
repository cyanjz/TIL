# ğŸ§ª ë°ì´í„° ë¶„ì„ ë° AI ëª¨ë¸ íŒŒì´í”„ë¼ì¸ í•µì‹¬ ë©”ì„œë“œ ì •ë¦¬

## âœ… 1. ë°ì´í„° ë¡œë”© & ì „ì²˜ë¦¬  
**ì‚¬ìš© ëª¨ë“ˆ**: `numpy`, `pandas`, `scipy`

### ğŸ¼ pandas
- `pd.read_csv()`, `pd.read_excel()`: ë°ì´í„° ë¡œë”©  
- `.info()`, `.describe()`: ë°ì´í„° ìš”ì•½  
- `.isnull()`, `.fillna()`, `.dropna()`: ê²°ì¸¡ê°’ ì²˜ë¦¬  
- `.astype()`, `.map()`, `.apply()`: íƒ€ì… ë³€í™˜  
- `.groupby()`, `.pivot_table()`: ì§‘ê³„  
- `.merge()`, `.concat()`: ë°ì´í„° ë³‘í•©  

### ğŸ”¢ numpy
- `np.array()`: ë°°ì—´ ìƒì„±  
- `np.isnan()`, `np.where()`: ê²°ì¸¡ê°’ ë° ì¡°ê±´ ì²˜ë¦¬  
- `np.mean()`, `np.std()`, `np.sum()`: í†µê³„  

### ğŸ“Š scipy
- `scipy.stats.zscore()`, `ttest_ind()`, `pearsonr()`: í†µê³„ ë¶„ì„  
- `scipy.sparse`: í¬ì†Œ í–‰ë ¬ ì²˜ë¦¬  

---

## âœ… 2. ë°ì´í„° ì‹œê°í™” & íƒìƒ‰  
**ì‚¬ìš© ëª¨ë“ˆ**: `matplotlib`, `pandas`

### ğŸ“ˆ matplotlib
- `plt.plot()`, `plt.bar()`, `plt.scatter()`, `plt.hist()`: ê¸°ë³¸ ì‹œê°í™”  
- `plt.title()`, `plt.xlabel()`, `plt.legend()`: ê¾¸ë¯¸ê¸°  
- `plt.subplot()`: ë‹¤ì¤‘ ê·¸ë˜í”„ êµ¬ì„±  

### ğŸ¼ pandas
- `.plot(kind='bar'/'hist'/'box')`: ê°„ë‹¨í•œ ì‹œê°í™”  

---

## âœ… 3. ë°ì´í„° ì „ì²˜ë¦¬ (í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í¬í•¨)  
**ì‚¬ìš© ëª¨ë“ˆ**: `pandas`, `scikit-learn`, `scipy`

### âš™ï¸ scikit-learn (preprocessing)
- `StandardScaler`, `MinMaxScaler`: ìŠ¤ì¼€ì¼ë§  
- `LabelEncoder`, `OneHotEncoder`: ì¸ì½”ë”©  
- `PolynomialFeatures`: ë‹¤í•­ í”¼ì²˜ ìƒì„±  
- `SimpleImputer`: ê²°ì¸¡ê°’ ëŒ€ì²´  

### ğŸ” scikit-learn (feature_selection)
- `SelectKBest`, `RFE`, `mutual_info_classif()`: í”¼ì²˜ ì„ íƒ  

---

## âœ… 4. ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ  
**ì‚¬ìš© ëª¨ë“ˆ**: `scikit-learn`, `xgboost`, `torch`, `torchvision`

### ğŸ”¬ scikit-learn (model_selection)
- `train_test_split`: ë°ì´í„° ë¶„ë¦¬  
- `GridSearchCV`, `RandomizedSearchCV`: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹  
- `cross_val_score`: êµì°¨ ê²€ì¦  

### ğŸ¤– scikit-learn (ëª¨ë¸)
- `LogisticRegression`, `RandomForestClassifier`, `SVC`: ë¶„ë¥˜  
- `LinearRegression`, `Ridge`, `Lasso`: íšŒê·€  

### ğŸš€ xgboost
- `XGBClassifier`, `XGBRegressor`  
- `.fit()`, `.predict()`, `.score()`, `.feature_importances_`  

### ğŸ”¥ PyTorch (`torch`, `torchvision`)
- `torch.nn`: ëª¨ë¸ êµ¬ì„± (ì˜ˆ: `nn.Linear`, `nn.ReLU`)  
- `torch.optim`: ì˜µí‹°ë§ˆì´ì € (`Adam`, `SGD`)  
- `torch.utils.data`: ë°ì´í„° ë¡œë”  
- `torchvision.transforms`: ì´ë¯¸ì§€ ì „ì²˜ë¦¬  
- `.train()`, `.eval()`, `.backward()`, `.step()`  

---

## âœ… 5. ëª¨ë¸ í‰ê°€  
**ì‚¬ìš© ëª¨ë“ˆ**: `scikit-learn`, `matplotlib`

### ğŸ“ scikit-learn (metrics)
- `accuracy_score`, `precision_score`, `recall_score`, `f1_score`: ë¶„ë¥˜ í‰ê°€  
- `confusion_matrix`, `classification_report`: ë¶„ë¥˜ ë¶„ì„  
- `mean_squared_error`, `r2_score`: íšŒê·€ í‰ê°€  
- `roc_auc_score`, `roc_curve`, `precision_recall_curve`: ì´ì§„ ë¶„ë¥˜  

### ğŸ“Š matplotlib
- ROC curve, confusion matrix ë“± ì‹œê°í™”  

---

## âœ… 6. ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°  
**ì‚¬ìš© ëª¨ë“ˆ**: `joblib`, `torch`, `xgboost`

### ğŸ’¾ joblib
- `joblib.dump(model, 'model.pkl')`: ì €ì¥  
- `joblib.load('model.pkl')`: ë¡œë“œ  

### ğŸ’¾ PyTorch
- `torch.save(model.state_dict(), 'model.pth')`  
- `model.load_state_dict(torch.load('model.pth'))`  

### ğŸ’¾ xgboost
- `.save_model()`, `.load_model()`  

---

## ğŸ§© ì „ì²´ ìš”ì•½ (ë‹¨ê³„ë³„ ì •ë¦¬)

| ë‹¨ê³„ | ì£¼ìš” ëª¨ë“ˆ | ì£¼ìš” ë©”ì„œë“œ |
|------|-----------|-------------|
| ë°ì´í„° ë¡œë”©/ì „ì²˜ë¦¬ | `pandas`, `numpy`, `scipy` | `read_csv`, `dropna`, `fillna`, `astype`, `zscore`, `where` |
| íƒìƒ‰/ì‹œê°í™” | `matplotlib`, `pandas` | `plot`, `hist`, `scatter`, `subplot`, `title` |
| ì „ì²˜ë¦¬ | `sklearn.preprocessing` | `StandardScaler`, `OneHotEncoder`, `PolynomialFeatures` |
| ëª¨ë¸ ì„ íƒ/í•™ìŠµ | `sklearn`, `xgboost`, `torch` | `fit`, `predict`, `train_test_split`, `cross_val_score`, `GridSearchCV` |
| ëª¨ë¸ í‰ê°€ | `sklearn.metrics` | `accuracy_score`, `confusion_matrix`, `roc_curve`, `r2_score` |
| ëª¨ë¸ ì €ì¥ | `joblib`, `torch`, `xgboost` | `dump`, `load`, `save_model`, `state_dict` |